# common variable & volume
x-airflow-common: &airflow-common
  image: frog-airflow:2.9.2-python3.12
  build:
    context: .
    dockerfile: airflow.Dockerfile
  user: "${AIRFLOW_UID:-1000}:0"
  environment:
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://quant:quant@db:5432/quant
    AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://quant:quant@db:5432/quant
    AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
    AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: Asia/Shanghai
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "true"
    AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT: "false"
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    # Make project packages (common/, download/, stock/, etc.) importable from DAGs
    PYTHONPATH: /opt/airflow/frog
    FROG_PROJECT_ROOT: /opt/airflow/frog
    # Email (required; define these in .env)
    AIRFLOW__SMTP__SMTP_HOST: ${SMTP_HOST:?SMTP_HOST is required}
    AIRFLOW__SMTP__SMTP_PORT: ${SMTP_PORT:?SMTP_PORT is required}
    AIRFLOW__SMTP__SMTP_USER: ${SMTP_USER:?SMTP_USER is required}
    AIRFLOW__SMTP__SMTP_PASSWORD: ${SMTP_PASSWORD:?SMTP_PASSWORD is required}
    AIRFLOW__SMTP__SMTP_MAIL_FROM: ${SMTP_MAIL_FROM:?SMTP_MAIL_FROM is required}
    ALERT_EMAILS: ${ALERT_EMAILS:?ALERT_EMAILS is required}
    # Repo email helper compatibility (utility.send_email)
    MAIL_SERVER: ${SMTP_HOST:?SMTP_HOST is required}
    MAIL_PORT: ${SMTP_PORT:?SMTP_PORT is required}
    MAIL_SENDER: ${SMTP_MAIL_FROM:?SMTP_MAIL_FROM is required}
    MAIL_PASSWORD: ${SMTP_PASSWORD:?SMTP_PASSWORD is required}
    MAIL_RECEIVERS: ${ALERT_EMAILS:?ALERT_EMAILS is required}
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./:/opt/airflow/frog
  depends_on:
    - db
    - redis
    - airflow-init-permissions

services:
  db:
    image: timescale/timescaledb:latest-pg16
    environment:
      POSTGRES_DB: quant
      POSTGRES_USER: quant
      POSTGRES_PASSWORD: quant
    ports: ["5432:5432"]
    volumes: ["db_data:/var/lib/postgresql/data"]

  redis:
    image: redis:7-alpine
    ports: ["6379:6379"]

  app:
    build: .
    depends_on: [db, redis]
    environment:
      DATABASE_URL: postgresql://quant:quant@db:5432/quant
      REDIS_URL: redis://redis:6379/0
    volumes: [".:/app"]

  airflow-init-permissions:
    image: busybox:latest
    user: root
    volumes:
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./dags:/opt/airflow/dags
    command: >
      sh -c "
        mkdir -p /opt/airflow/logs /opt/airflow/plugins /opt/airflow/dags &&
        chown -R ${AIRFLOW_UID:-1000}:0 /opt/airflow/logs /opt/airflow/plugins /opt/airflow/dags &&
        echo 'Permissions fixed successfully!'
      "

  airflow-webserver:
    <<: *airflow-common
    ports: ["8080:8080"]
    command: >
      bash -c "airflow db init && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || echo 'User already exists or db already initialized'; airflow webserver"
    depends_on:
      - db
      - redis

  airflow-scheduler:
    <<: *airflow-common
    command: >
      bash -c "airflow db upgrade || echo 'DB already upgraded'; airflow scheduler"
    depends_on:
      - db
      - redis
      - airflow-webserver

  airflow-worker:
    <<: *airflow-common
    command: >
      bash -c "airflow db upgrade || echo 'DB already upgraded'; airflow celery worker"
    depends_on:
      - db
      - redis
      - airflow-webserver

  airflow-init:
    <<: *airflow-common
    command: >
      bash -c "airflow db init && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || echo 'User already exists'"
    profiles: ["init"]
    restart: "no"

volumes:
  db_data:
