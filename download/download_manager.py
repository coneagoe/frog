import logging

import pandas as pd

from common.const import COL_DATE, COL_STOCK_ID, AdjustType, PeriodType
from storage import (
    get_storage,
    tb_name_general_info_stock,
    tb_name_history_data_daily_a_stock_hfq,
    tb_name_history_data_daily_a_stock_qfq,
    tb_name_history_data_daily_hk_stock_hfq,
    tb_name_history_data_monthly_hk_stock_hfq,
    tb_name_history_data_weekly_a_stock_hfq,
    tb_name_history_data_weekly_a_stock_qfq,
    tb_name_history_data_weekly_hk_stock_hfq,
    tb_name_ingredient_300,
    tb_name_ingredient_500,
)
from storage.model import (
    tb_name_history_data_daily_etf_hfq,
    tb_name_history_data_daily_etf_qfq,
    tb_name_history_data_weekly_etf_hfq,
    tb_name_history_data_weekly_etf_qfq,
)

from .dl import Downloader


class DownloadManager:
    def __init__(self):
        storage = get_storage()

        self.storage = storage
        self.downloader = Downloader()

    def download_general_info_stock(self, force: bool = False) -> bool:
        self.storage.drop_table(tb_name_general_info_stock)

        df = self.downloader.dl_general_info_stock()
        if df is None or df.empty:
            logging.warning("Failed to download stock info or data is empty.")
            return False

        return self.storage.save_general_info_stock(df)

    def download_general_info_etf(self, force: bool = False) -> bool:
        df = self.downloader.dl_general_info_etf()
        if df is None or df.empty:
            logging.warning("Failed to download ETF info or data is empty.")
            return False

        return self.storage.save_general_info_etf(df)

    def download_general_info_hk_ggt(self, force: bool = False) -> bool:
        df = self.downloader.dl_general_info_hk_ggt_stock()
        if df is None or df.empty:
            logging.warning("Failed to download HK GGT info or data is empty.")
            return False

        return self.storage.save_general_info_hk_ggt(df)

    def download_stock_history(
        self,
        stock_id: str,
        period: PeriodType,
        start_date: str,
        end_date: str,
        adjust: AdjustType = AdjustType.QFQ,
    ) -> bool:
        if adjust == AdjustType.QFQ:
            table_name = (
                tb_name_history_data_daily_a_stock_qfq
                if period == PeriodType.DAILY
                else tb_name_history_data_weekly_a_stock_qfq
            )
        else:
            table_name = (
                tb_name_history_data_daily_a_stock_hfq
                if period == PeriodType.DAILY
                else tb_name_history_data_weekly_a_stock_hfq
            )

        try:
            last_record = self.storage.get_last_record(table_name, stock_id)

            if last_record is not None:
                latest_date = pd.Timestamp(last_record[COL_DATE])
                actual_start_date = (latest_date + pd.Timedelta(days=1)).strftime(
                    "%Y%m%d"
                )

                if actual_start_date > end_date:
                    logging.info(f"Data for {stock_id} is already up to date")
                    return True
            else:
                actual_start_date = start_date

            df = self.downloader.dl_history_data_stock(
                stock_id, actual_start_date, end_date, period, adjust
            )

            if df is None or df.empty:
                logging.info(f"No new data for {stock_id}")
                return True

            return self.storage.save_history_data_stock(df, period, adjust)

        except Exception as e:
            logging.error(f"Error processing history for {stock_id}: {e}")
            return False

    def download_all_stock_history(
        self,
        period: PeriodType = PeriodType.DAILY,
        adjust: AdjustType = AdjustType.QFQ,
        start_date: str = "2000-01-01",
        end_date: str = None,
    ) -> bool:
        """
        ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨çš„å†å²æ•°æ®

        Args:
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨/æœˆï¼‰
            adjust: å¤æƒç±»å‹ï¼ˆå‰å¤æƒ/åå¤æƒï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2000-01-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å¤©

        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆæ‰€æœ‰è‚¡ç¥¨çš„ä¸‹è½½
        """
        if end_date is None:
            from datetime import datetime

            end_date = datetime.now().strftime("%Y-%m-%d")

        logging.info(
            f"å¼€å§‹ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨å†å²æ•°æ®ï¼Œå‘¨æœŸ: {period.value}, å¤æƒ: {adjust.value}, æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}"
        )

        try:
            if adjust == AdjustType.QFQ:
                table_name = (
                    tb_name_history_data_daily_a_stock_qfq
                    if period == PeriodType.DAILY
                    else tb_name_history_data_weekly_a_stock_qfq
                )
                self.storage.drop_table(table_name)

            df_stocks = self.storage.load_general_info_stock()

            if df_stocks is None or df_stocks.empty:
                logging.error("æ— æ³•è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æ•°æ®")
                return False

            stock_ids = df_stocks[COL_STOCK_ID].tolist()
            total_stocks = len(stock_ids)

            logging.info(f"å…±è·å–åˆ° {total_stocks} åªè‚¡ç¥¨ï¼Œå¼€å§‹æ‰¹é‡ä¸‹è½½å†å²æ•°æ®...")

            success_count = 0
            failure_count = 0

            for i, stock_id in enumerate(stock_ids, 1):
                try:
                    logging.info(f"æ­£åœ¨ä¸‹è½½ç¬¬ {i}/{total_stocks} åªè‚¡ç¥¨: {stock_id}")

                    success = self.download_stock_history(
                        stock_id=stock_id,
                        period=period,
                        start_date=start_date,
                        end_date=end_date,
                        adjust=adjust,
                    )

                    if success:
                        success_count += 1
                        logging.info(f"âœ“ è‚¡ç¥¨ {stock_id} ä¸‹è½½æˆåŠŸ ({i}/{total_stocks})")
                    else:
                        failure_count += 1
                        logging.warning(
                            f"âš  è‚¡ç¥¨ {stock_id} ä¸‹è½½å¤±è´¥ ({i}/{total_stocks})"
                        )

                except Exception as e:
                    failure_count += 1
                    logging.error(
                        f"âœ— è‚¡ç¥¨ {stock_id} ä¸‹è½½å‡ºé”™: {e} ({i}/{total_stocks})"
                    )

            # æ€»ç»“ä¸‹è½½ç»“æœ
            logging.info(
                f"æ‰¹é‡ä¸‹è½½å®Œæˆï¼æˆåŠŸ: {success_count}, å¤±è´¥: {failure_count}, æ€»è®¡: {total_stocks}"
            )

            if failure_count == 0:
                logging.info("ğŸ‰ æ‰€æœ‰è‚¡ç¥¨å†å²æ•°æ®ä¸‹è½½æˆåŠŸï¼")
                return True
            else:
                logging.warning(
                    f"âš  éƒ¨åˆ†è‚¡ç¥¨ä¸‹è½½å¤±è´¥ï¼ŒæˆåŠŸç‡: {success_count/total_stocks*100:.1f}%"
                )
                return False

        except Exception as e:
            logging.error(f"æ‰¹é‡ä¸‹è½½è‚¡ç¥¨å†å²æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def download_hk_stock_history(
        self,
        stock_id: str,
        period: PeriodType,
        start_date: str,
        end_date: str,
        adjust: AdjustType = AdjustType.HFQ,
    ) -> bool:
        """
        ä¸‹è½½é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®

        Args:
            stock_id: é¦™æ¸¯è‚¡ç¥¨ä»£ç  (5ä½æ•°å­—)
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨/æœˆï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            adjust: å¤æƒç±»å‹ï¼ˆé»˜è®¤åå¤æƒï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        # æ ¹æ®å‘¨æœŸé€‰æ‹©å¯¹åº”çš„è¡¨å
        if period == PeriodType.DAILY:
            table_name = tb_name_history_data_daily_hk_stock_hfq
        elif period == PeriodType.WEEKLY:
            table_name = tb_name_history_data_weekly_hk_stock_hfq
        elif period == PeriodType.MONTHLY:
            table_name = tb_name_history_data_monthly_hk_stock_hfq
        else:
            logging.error(f"ä¸æ”¯æŒçš„å‘¨æœŸç±»å‹: {period}")
            return False

        try:
            # è·å–æœ€åä¸€æ¡è®°å½•ä»¥å®ç°å¢é‡æ›´æ–°
            last_record = self.storage.get_last_record(table_name, stock_id)

            if last_record is not None:
                latest_date = pd.Timestamp(last_record[COL_DATE])
                actual_start_date = (latest_date + pd.Timedelta(days=1)).strftime(
                    "%Y-%m-%d"
                )

                if actual_start_date > end_date:
                    logging.info(f"é¦™æ¸¯è‚¡ç¥¨ {stock_id} æ•°æ®å·²æ˜¯æœ€æ–°")
                    return True
            else:
                actual_start_date = start_date

            # ä¸‹è½½é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®
            df = self.downloader.dl_history_data_stock_hk(
                stock_id, actual_start_date, end_date, period, adjust
            )

            if df is None or df.empty:
                logging.info(f"é¦™æ¸¯è‚¡ç¥¨ {stock_id} æ— æ–°æ•°æ®")
                return True

            # ä¿å­˜æ•°æ®åˆ°å¯¹åº”çš„é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®è¡¨
            return self.storage.save_history_data_hk_stock(df, period, adjust)

        except Exception as e:
            logging.error(f"å¤„ç†é¦™æ¸¯è‚¡ç¥¨ {stock_id} å†å²æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def download_all_hk_stock_history(
        self,
        period: PeriodType = PeriodType.DAILY,
        adjust: AdjustType = AdjustType.HFQ,
        start_date: str = "2000-01-01",
        end_date: str = None,
    ) -> bool:
        """
        ä¸‹è½½æ‰€æœ‰é¦™æ¸¯è‚¡ç¥¨çš„å†å²æ•°æ®

        Args:
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨/æœˆï¼‰
            adjust: å¤æƒç±»å‹ï¼ˆé»˜è®¤åå¤æƒï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2000-01-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å¤©

        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆæ‰€æœ‰é¦™æ¸¯è‚¡ç¥¨çš„ä¸‹è½½
        """
        if end_date is None:
            from datetime import datetime

            end_date = datetime.now().strftime("%Y-%m-%d")

        logging.info(
            f"å¼€å§‹ä¸‹è½½æ‰€æœ‰é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®ï¼Œå‘¨æœŸ: {period.value}, å¤æƒ: {adjust.value}, æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}"
        )

        try:
            if adjust == AdjustType.QFQ:
                table_name = (
                    tb_name_history_data_daily_hk_stock_hfq
                    if period == PeriodType.DAILY
                    else tb_name_history_data_weekly_hk_stock_hfq
                )
                self.storage.drop_table(table_name)

            df_hk_stocks = self.storage.load_general_info_hk_ggt()

            if df_hk_stocks is None or df_hk_stocks.empty:
                logging.error("æ— æ³•è·å–é¦™æ¸¯è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æ•°æ®")
                return False

            stock_ids = df_hk_stocks[COL_STOCK_ID].tolist()
            total_stocks = len(stock_ids)

            logging.info(f"å…±è·å–åˆ° {total_stocks} åªé¦™æ¸¯è‚¡ç¥¨ï¼Œå¼€å§‹æ‰¹é‡ä¸‹è½½å†å²æ•°æ®...")

            success_count = 0
            failure_count = 0

            for i, stock_id in enumerate(stock_ids, 1):
                try:
                    logging.info(
                        f"æ­£åœ¨ä¸‹è½½ç¬¬ {i}/{total_stocks} åªé¦™æ¸¯è‚¡ç¥¨: {stock_id}"
                    )

                    success = self.download_hk_stock_history(
                        stock_id=stock_id,
                        period=period,
                        start_date=start_date,
                        end_date=end_date,
                        adjust=adjust,
                    )

                    if success:
                        success_count += 1
                        logging.info(
                            f"âœ“ é¦™æ¸¯è‚¡ç¥¨ {stock_id} ä¸‹è½½æˆåŠŸ ({i}/{total_stocks})"
                        )
                    else:
                        failure_count += 1
                        logging.warning(
                            f"âš  é¦™æ¸¯è‚¡ç¥¨ {stock_id} ä¸‹è½½å¤±è´¥ ({i}/{total_stocks})"
                        )

                except Exception as e:
                    failure_count += 1
                    logging.error(
                        f"âœ— é¦™æ¸¯è‚¡ç¥¨ {stock_id} ä¸‹è½½å‡ºé”™: {e} ({i}/{total_stocks})"
                    )

            # æ€»ç»“ä¸‹è½½ç»“æœ
            logging.info(
                f"é¦™æ¸¯è‚¡ç¥¨æ‰¹é‡ä¸‹è½½å®Œæˆï¼æˆåŠŸ: {success_count}, å¤±è´¥: {failure_count}, æ€»è®¡: {total_stocks}"
            )

            if failure_count == 0:
                logging.info("ğŸ‰ æ‰€æœ‰é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®ä¸‹è½½æˆåŠŸï¼")
                return True
            else:
                logging.warning(
                    f"âš  éƒ¨åˆ†é¦™æ¸¯è‚¡ç¥¨ä¸‹è½½å¤±è´¥ï¼ŒæˆåŠŸç‡: {success_count/total_stocks*100:.1f}%"
                )
                return False

        except Exception as e:
            logging.error(f"æ‰¹é‡ä¸‹è½½é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def download_etf_history(
        self,
        etf_id: str,
        period: PeriodType,
        start_date: str,
        end_date: str,
        adjust: AdjustType = AdjustType.QFQ,
    ) -> bool:
        """
        ä¸‹è½½ETFå†å²æ•°æ®

        Args:
            etf_id: ETFä»£ç 
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨ï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            adjust: å¤æƒç±»å‹ï¼ˆå‰å¤æƒ/åå¤æƒï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        # æ ¹æ®å¤æƒç±»å‹é€‰æ‹©å¯¹åº”çš„è¡¨å
        if adjust == AdjustType.QFQ:
            table_name = (
                tb_name_history_data_daily_etf_qfq
                if period == PeriodType.DAILY
                else tb_name_history_data_weekly_etf_qfq
            )
        else:
            table_name = (
                tb_name_history_data_daily_etf_hfq
                if period == PeriodType.DAILY
                else tb_name_history_data_weekly_etf_hfq
            )

        try:
            # è·å–æœ€åä¸€æ¡è®°å½•ä»¥å®ç°å¢é‡æ›´æ–°
            last_record = self.storage.get_last_record(table_name, etf_id)

            if last_record is not None:
                latest_date = pd.Timestamp(last_record[COL_DATE])
                actual_start_date = (latest_date + pd.Timedelta(days=1)).strftime(
                    "%Y%m%d"
                )

                if actual_start_date > end_date:
                    logging.info(f"ETF {etf_id} æ•°æ®å·²æ˜¯æœ€æ–°")
                    return True
            else:
                actual_start_date = start_date

            # ä¸‹è½½ETFå†å²æ•°æ®
            df = self.downloader.dl_history_data_etf(
                etf_id, actual_start_date, end_date, period, adjust
            )

            if df is None or df.empty:
                logging.info(f"ETF {etf_id} æ— æ–°æ•°æ®")
                return True

            # ä¿å­˜æ•°æ®åˆ°å¯¹åº”çš„ETFå†å²æ•°æ®è¡¨
            return self.storage.save_history_data_etf(df, period, adjust)

        except Exception as e:
            logging.error(f"å¤„ç†ETF {etf_id} å†å²æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def download_all_etf_history(
        self,
        period: PeriodType = PeriodType.DAILY,
        adjust: AdjustType = AdjustType.QFQ,
        start_date: str = "2000-01-01",
        end_date: str = None,
    ) -> bool:
        """
        ä¸‹è½½æ‰€æœ‰ETFçš„å†å²æ•°æ®

        Args:
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨ï¼‰
            adjust: å¤æƒç±»å‹ï¼ˆå‰å¤æƒ/åå¤æƒï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2000-01-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å¤©

        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆæ‰€æœ‰ETFçš„ä¸‹è½½
        """
        if end_date is None:
            from datetime import datetime

            end_date = datetime.now().strftime("%Y-%m-%d")

        logging.info(
            f"å¼€å§‹ä¸‹è½½æ‰€æœ‰ETFå†å²æ•°æ®ï¼Œå‘¨æœŸ: {period.value}, å¤æƒ: {adjust.value}, æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}"
        )

        try:
            if adjust == AdjustType.QFQ:
                table_name = (
                    tb_name_history_data_daily_etf_qfq
                    if period == PeriodType.DAILY
                    else tb_name_history_data_weekly_etf_qfq
                )
                self.storage.drop_table(table_name)

            # è·å–ETFåŸºæœ¬ä¿¡æ¯
            df_etfs = self.storage.load_general_info_etf()

            if df_etfs is None or df_etfs.empty:
                logging.error("æ— æ³•è·å–ETFåŸºæœ¬ä¿¡æ¯æ•°æ®")
                return False

            etf_ids = df_etfs[COL_STOCK_ID].tolist()
            total_etfs = len(etf_ids)

            logging.info(f"å…±è·å–åˆ° {total_etfs} åªETFï¼Œå¼€å§‹æ‰¹é‡ä¸‹è½½å†å²æ•°æ®...")

            success_count = 0
            failure_count = 0

            for i, etf_id in enumerate(etf_ids, 1):
                try:
                    logging.info(f"æ­£åœ¨ä¸‹è½½ç¬¬ {i}/{total_etfs} åªETF: {etf_id}")

                    success = self.download_etf_history(
                        etf_id=etf_id,
                        period=period,
                        start_date=start_date,
                        end_date=end_date,
                        adjust=adjust,
                    )

                    if success:
                        success_count += 1
                        logging.info(f"âœ“ ETF {etf_id} ä¸‹è½½æˆåŠŸ ({i}/{total_etfs})")
                    else:
                        failure_count += 1
                        logging.warning(f"âš  ETF {etf_id} ä¸‹è½½å¤±è´¥ ({i}/{total_etfs})")

                except Exception as e:
                    failure_count += 1
                    logging.error(f"âœ— ETF {etf_id} ä¸‹è½½å‡ºé”™: {e} ({i}/{total_etfs})")

            # æ€»ç»“ä¸‹è½½ç»“æœ
            logging.info(
                f"ETFæ‰¹é‡ä¸‹è½½å®Œæˆï¼æˆåŠŸ: {success_count}, å¤±è´¥: {failure_count}, æ€»è®¡: {total_etfs}"
            )

            if failure_count == 0:
                logging.info("ğŸ‰ æ‰€æœ‰ETFå†å²æ•°æ®ä¸‹è½½æˆåŠŸï¼")
                return True
            else:
                logging.warning(
                    f"âš  éƒ¨åˆ†ETFä¸‹è½½å¤±è´¥ï¼ŒæˆåŠŸç‡: {success_count/total_etfs*100:.1f}%"
                )
                return False

        except Exception as e:
            logging.error(f"æ‰¹é‡ä¸‹è½½ETFå†å²æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def download_ingredient_300(self) -> bool:
        """
        ä¸‹è½½æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®

        Args:
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼ˆåˆ é™¤ç°æœ‰æ•°æ®ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        self.storage.drop_table(tb_name_ingredient_300)

        try:
            # ä¸‹è½½æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®
            df = self.downloader.dl_ingredient_300()
            if df is None or df.empty:
                logging.warning(
                    "Failed to download CSI 300 ingredient data or data is empty."
                )
                return False

            # ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“
            return self.storage.save_ingredient_300(df)

        except Exception as e:
            logging.error(f"ä¸‹è½½æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def download_ingredient_500(self) -> bool:
        """
        ä¸‹è½½ä¸­è¯500æˆåˆ†è‚¡æ•°æ®

        Args:
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼ˆåˆ é™¤ç°æœ‰æ•°æ®ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        self.storage.drop_table(tb_name_ingredient_500)

        try:
            # ä¸‹è½½ä¸­è¯500æˆåˆ†è‚¡æ•°æ®
            df = self.downloader.dl_ingredient_500()
            if df is None or df.empty:
                logging.warning(
                    "Failed to download CSI 500 ingredient data or data is empty."
                )
                return False

            # ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“
            return self.storage.save_ingredient_500(df)

        except Exception as e:
            logging.error(f"ä¸‹è½½ä¸­è¯500æˆåˆ†è‚¡æ•°æ®æ—¶å‡ºé”™: {e}")
            return False
