import logging
from datetime import datetime
from typing import Any, Callable

import pandas as pd

from common.const import COL_DATE, COL_STOCK_ID, AdjustType, PeriodType, SecurityType
from storage import (
    get_storage,
    get_table_name,
    tb_name_general_info_stock,
    tb_name_ingredient_300,
    tb_name_ingredient_500,
)

from .dl import Downloader
from .mp_utils import run_history_download_mp


class DownloadManager:
    def __init__(self):
        self.downloader = Downloader()

    def download_general_info_stock(self) -> bool:
        get_storage().drop_table(tb_name_general_info_stock)

        df = self.downloader.dl_general_info_stock()
        if df is None or df.empty:
            logging.warning("Failed to download stock info or data is empty.")
            return False

        return get_storage().save_general_info_stock(df)

    def download_general_info_etf(self) -> bool:
        df = self.downloader.dl_general_info_etf()
        if df is None or df.empty:
            logging.warning("Failed to download ETF info or data is empty.")
            return False

        return get_storage().save_general_info_etf(df)

    def download_general_info_hk_ggt(self) -> bool:
        df = self.downloader.dl_general_info_hk_ggt_stock()
        if df is None or df.empty:
            logging.warning("Failed to download HK GGT info or data is empty.")
            return False

        return get_storage().save_general_info_hk_ggt(df)

    def _download_history_data(
        self,
        table_name: str,
        security_id: str,
        period: PeriodType,
        start_date: str,
        end_date: str,
        adjust: AdjustType,
        downloader_func: Callable[[str, str, str, PeriodType, AdjustType], Any],
        storage_save_func: Callable[[Any, PeriodType, AdjustType], bool],
    ) -> bool:
        try:
            last_record = get_storage().get_last_record(table_name, security_id)

            if last_record is not None:
                latest_date = pd.Timestamp(last_record[COL_DATE])
                actual_start_ts = latest_date + pd.Timedelta(days=1)
                actual_start_date = actual_start_ts.strftime("%Y%m%d")

                if actual_start_ts > pd.to_datetime(end_date):
                    logging.info(f"Data for {security_id} is already up to date")
                    return True
            else:
                actual_start_date = start_date

            df = downloader_func(
                security_id, actual_start_date, end_date, period, adjust
            )

            if df is None or df.empty:
                logging.info(f"No new data for {security_id}")
                return True

            return storage_save_func(df, period, adjust)

        except Exception as e:
            logging.error(f"Error processing history for {security_id}: {e}")
            return False

    def download_stock_history(
        self,
        stock_id: str,
        period: PeriodType,
        start_date: str,
        end_date: str,
        adjust: AdjustType = AdjustType.QFQ,
    ) -> bool:
        table_name = get_table_name(SecurityType.STOCK, period, adjust)

        return self._download_history_data(
            table_name=table_name,
            security_id=stock_id,
            period=period,
            start_date=start_date,
            end_date=end_date,
            adjust=adjust,
            downloader_func=self.downloader.dl_history_data_stock,
            storage_save_func=get_storage().save_history_data_stock,
        )

    def download_all_stock_history(
        self,
        period: PeriodType = PeriodType.DAILY,
        adjust: AdjustType = AdjustType.QFQ,
        start_date: str = "2000-01-01",
        end_date: str = None,
    ) -> bool:
        """
        ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨çš„å†å²æ•°æ®

        Args:
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨/æœˆï¼‰
            adjust: å¤æƒç±»å‹ï¼ˆå‰å¤æƒ/åå¤æƒï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2000-01-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å¤©

        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆæ‰€æœ‰è‚¡ç¥¨çš„ä¸‹è½½
        """
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")

        logging.info(
            f"å¼€å§‹ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨å†å²æ•°æ®ï¼Œå‘¨æœŸ: {period.value}, å¤æƒ: {adjust.value}, æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}"
        )

        table_name = get_table_name(SecurityType.STOCK, period, adjust)

        try:
            if adjust == AdjustType.QFQ:
                get_storage().drop_table(table_name)

            df_stocks = get_storage().load_general_info_stock()

            if df_stocks is None or df_stocks.empty:
                logging.error("æ— æ³•è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æ•°æ®")
                return False

            stock_ids = df_stocks[COL_STOCK_ID].tolist()
            total_stocks = len(stock_ids)

            logging.info(f"å…±è·å–åˆ° {total_stocks} åªè‚¡ç¥¨ï¼Œå¼€å§‹å¤šè¿›ç¨‹ä¸‹è½½å†å²æ•°æ®...")

            result = run_history_download_mp(
                security_type=SecurityType.STOCK,
                ids=stock_ids,
                period_value=period.value,
                adjust_value=adjust.value,
                start_date=start_date,
                end_date=end_date,
                process_count=None,
                log_prefix="[Aè‚¡] ",
            )

            if result.failed == 0:
                logging.info("ğŸ‰ æ‰€æœ‰è‚¡ç¥¨å†å²æ•°æ®ä¸‹è½½æˆåŠŸï¼")
                return True

            logging.warning(
                f"âš  éƒ¨åˆ†è‚¡ç¥¨ä¸‹è½½å¤±è´¥ï¼ŒæˆåŠŸç‡: {result.success/total_stocks*100:.1f}%"
            )
            return False

        except Exception as e:
            logging.error(f"æ‰¹é‡ä¸‹è½½è‚¡ç¥¨å†å²æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def download_hk_stock_history(
        self,
        stock_id: str,
        period: PeriodType,
        start_date: str,
        end_date: str,
        adjust: AdjustType = AdjustType.HFQ,
    ) -> bool:
        """
        ä¸‹è½½é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®

        Args:
            stock_id: é¦™æ¸¯è‚¡ç¥¨ä»£ç  (5ä½æ•°å­—)
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨/æœˆï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            adjust: å¤æƒç±»å‹ï¼ˆé»˜è®¤åå¤æƒï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        table_name = get_table_name(SecurityType.HK_GGT_STOCK, period, adjust)

        return self._download_history_data(
            table_name=table_name,
            security_id=stock_id,
            period=period,
            start_date=start_date,
            end_date=end_date,
            adjust=adjust,
            downloader_func=self.downloader.dl_history_data_stock_hk,
            storage_save_func=get_storage().save_history_data_hk_stock,
        )

    def download_all_hk_stock_history(
        self,
        period: PeriodType = PeriodType.DAILY,
        adjust: AdjustType = AdjustType.HFQ,
        start_date: str = "2000-01-01",
        end_date: str = None,
    ) -> bool:
        """
        ä¸‹è½½æ‰€æœ‰é¦™æ¸¯è‚¡ç¥¨çš„å†å²æ•°æ®

        Args:
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨/æœˆï¼‰
            adjust: å¤æƒç±»å‹ï¼ˆé»˜è®¤åå¤æƒï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2000-01-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å¤©

        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆæ‰€æœ‰é¦™æ¸¯è‚¡ç¥¨çš„ä¸‹è½½
        """
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")

        logging.info(
            f"å¼€å§‹ä¸‹è½½æ‰€æœ‰é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®ï¼Œå‘¨æœŸ: {period.value}, å¤æƒ: {adjust.value}, æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}"
        )

        table_name = get_table_name(SecurityType.HK_GGT_STOCK, period, adjust)
        try:
            if adjust == AdjustType.QFQ:
                get_storage().drop_table(table_name)

            df_hk_stocks = get_storage().load_general_info_hk_ggt()

            if df_hk_stocks is None or df_hk_stocks.empty:
                logging.error("æ— æ³•è·å–é¦™æ¸¯è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æ•°æ®")
                return False

            stock_ids = df_hk_stocks[COL_STOCK_ID].tolist()
            total_stocks = len(stock_ids)

            logging.info(
                f"å…±è·å–åˆ° {total_stocks} åªé¦™æ¸¯è‚¡ç¥¨ï¼Œå¼€å§‹å¤šè¿›ç¨‹ä¸‹è½½å†å²æ•°æ®..."
            )

            result = run_history_download_mp(
                security_type=SecurityType.HK_GGT_STOCK,
                ids=stock_ids,
                period_value=period.value,
                adjust_value=adjust.value,
                start_date=start_date,
                end_date=end_date,
                process_count=None,
                log_prefix="[æ¸¯è‚¡] ",
            )

            if result.failed == 0:
                logging.info("ğŸ‰ æ‰€æœ‰é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®ä¸‹è½½æˆåŠŸï¼")
                return True

            logging.warning(
                f"âš  éƒ¨åˆ†é¦™æ¸¯è‚¡ç¥¨ä¸‹è½½å¤±è´¥ï¼ŒæˆåŠŸç‡: {result.success/total_stocks*100:.1f}%"
            )
            return False

        except Exception as e:
            logging.error(f"æ‰¹é‡ä¸‹è½½é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def download_etf_history(
        self,
        etf_id: str,
        period: PeriodType,
        start_date: str,
        end_date: str,
        adjust: AdjustType = AdjustType.QFQ,
    ) -> bool:
        """
        ä¸‹è½½ETFå†å²æ•°æ®

        Args:
            etf_id: ETFä»£ç 
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨ï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            adjust: å¤æƒç±»å‹ï¼ˆå‰å¤æƒ/åå¤æƒï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        table_name = get_table_name(SecurityType.ETF, period, adjust)

        return self._download_history_data(
            table_name=table_name,
            security_id=etf_id,
            period=period,
            start_date=start_date,
            end_date=end_date,
            adjust=adjust,
            downloader_func=self.downloader.dl_history_data_etf,
            storage_save_func=get_storage().save_history_data_etf,
        )

    def download_all_etf_history(
        self,
        period: PeriodType = PeriodType.DAILY,
        adjust: AdjustType = AdjustType.QFQ,
        start_date: str = "2000-01-01",
        end_date: str = None,
    ) -> bool:
        """
        ä¸‹è½½æ‰€æœ‰ETFçš„å†å²æ•°æ®

        Args:
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨ï¼‰
            adjust: å¤æƒç±»å‹ï¼ˆå‰å¤æƒ/åå¤æƒï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2000-01-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å¤©

        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆæ‰€æœ‰ETFçš„ä¸‹è½½
        """
        if end_date is None:
            from datetime import datetime

            end_date = datetime.now().strftime("%Y-%m-%d")

        logging.info(
            f"å¼€å§‹ä¸‹è½½æ‰€æœ‰ETFå†å²æ•°æ®ï¼Œå‘¨æœŸ: {period.value}, å¤æƒ: {adjust.value}, æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}"
        )

        table_name = get_table_name(SecurityType.ETF, period, adjust)

        try:
            if adjust == AdjustType.QFQ:
                get_storage().drop_table(table_name)

            # è·å–ETFåŸºæœ¬ä¿¡æ¯
            df_etfs = get_storage().load_general_info_etf()

            if df_etfs is None or df_etfs.empty:
                logging.error("æ— æ³•è·å–ETFåŸºæœ¬ä¿¡æ¯æ•°æ®")
                return False

            etf_ids = df_etfs[COL_STOCK_ID].tolist()
            total_etfs = len(etf_ids)

            logging.info(f"å…±è·å–åˆ° {total_etfs} åªETFï¼Œå¼€å§‹å¤šè¿›ç¨‹ä¸‹è½½å†å²æ•°æ®...")

            result = run_history_download_mp(
                security_type=SecurityType.ETF,
                ids=etf_ids,
                period_value=period.value,
                adjust_value=adjust.value,
                start_date=start_date,
                end_date=end_date,
                process_count=None,
                log_prefix="[ETF] ",
            )

            if result.failed == 0:
                logging.info("ğŸ‰ æ‰€æœ‰ETFå†å²æ•°æ®ä¸‹è½½æˆåŠŸï¼")
                return True

            logging.warning(
                f"âš  éƒ¨åˆ†ETFä¸‹è½½å¤±è´¥ï¼ŒæˆåŠŸç‡: {result.success/total_etfs*100:.1f}%"
            )
            return False

        except Exception as e:
            logging.error(f"æ‰¹é‡ä¸‹è½½ETFå†å²æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def download_ingredient_300(self) -> bool:
        """
        ä¸‹è½½æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        get_storage().drop_table(tb_name_ingredient_300)

        try:
            # ä¸‹è½½æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®
            df = self.downloader.dl_ingredient_300()
            if df is None or df.empty:
                logging.warning(
                    "Failed to download CSI 300 ingredient data or data is empty."
                )
                return False

            # ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“
            return get_storage().save_ingredient_300(df)

        except Exception as e:
            logging.error(f"ä¸‹è½½æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def download_ingredient_500(self) -> bool:
        """
        ä¸‹è½½ä¸­è¯500æˆåˆ†è‚¡æ•°æ®

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        get_storage().drop_table(tb_name_ingredient_500)

        try:
            df = self.downloader.dl_ingredient_500()
            if df is None or df.empty:
                logging.warning(
                    "Failed to download CSI 500 ingredient data or data is empty."
                )
                return False

            return get_storage().save_ingredient_500(df)

        except Exception as e:
            logging.error(f"ä¸‹è½½ä¸­è¯500æˆåˆ†è‚¡æ•°æ®æ—¶å‡ºé”™: {e}")
            return False
