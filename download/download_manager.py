import logging
from datetime import datetime
from typing import Any, Callable

import pandas as pd
import pandas_market_calendars as mcal

from common.const import COL_DATE, COL_STOCK_ID, AdjustType, PeriodType, SecurityType
from storage import (
    get_storage,
    get_table_name,
    tb_name_general_info_stock,
    tb_name_ingredient_300,
    tb_name_ingredient_500,
)
from storage.model import (
    tb_name_a_stock_basic,
    tb_name_daily_basic_a_stock,
    tb_name_stk_limit_a_stock,
    tb_name_suspend_d_a_stock,
)

from .dl import Downloader
from .mp_utils import run_history_download_mp


class DownloadManager:
    def __init__(self):
        self.downloader = Downloader()

    def download_general_info_stock(self) -> bool:
        get_storage().drop_table(tb_name_general_info_stock)

        df = self.downloader.dl_general_info_stock()
        if df is None or df.empty:
            logging.warning("Failed to download stock info or data is empty.")
            return False

        return get_storage().save_general_info_stock(df)

    def download_general_info_etf(self) -> bool:
        df = self.downloader.dl_general_info_etf()
        if df is None or df.empty:
            logging.warning("Failed to download ETF info or data is empty.")
            return False

        return get_storage().save_general_info_etf(df)

    def download_general_info_hk_ggt(self) -> bool:
        df = self.downloader.dl_general_info_hk_ggt_stock()
        if df is None or df.empty:
            logging.warning("Failed to download HK GGT info or data is empty.")
            return False

        return get_storage().save_general_info_hk_ggt(df)

    def _download_history_data(
        self,
        table_name: str,
        security_id: str,
        period: PeriodType,
        start_date: str,
        end_date: str,
        adjust: AdjustType,
        downloader_func: Callable[[str, str, str, PeriodType, AdjustType], Any],
        storage_save_func: Callable[[Any, PeriodType, AdjustType], bool],
    ) -> bool:
        try:
            last_record = get_storage().get_last_record(table_name, security_id)

            if last_record is not None:
                latest_date = pd.Timestamp(last_record[COL_DATE])
                actual_start_ts = latest_date + pd.Timedelta(days=1)
                actual_start_date = actual_start_ts.strftime("%Y%m%d")

                if actual_start_ts > pd.to_datetime(end_date):
                    logging.info(f"Data for {security_id} is already up to date")
                    return True
            else:
                actual_start_date = start_date

            df = downloader_func(
                security_id, actual_start_date, end_date, period, adjust
            )

            if df is None or df.empty:
                logging.info(f"No new data for {security_id}")
                return True

            return storage_save_func(df, period, adjust)

        except Exception as e:
            logging.error(f"Error processing history for {security_id}: {e}")
            return False

    def download_stock_history(
        self,
        stock_id: str,
        period: PeriodType,
        start_date: str,
        end_date: str,
        adjust: AdjustType = AdjustType.QFQ,
    ) -> bool:
        table_name = get_table_name(SecurityType.STOCK, period, adjust)

        return self._download_history_data(
            table_name=table_name,
            security_id=stock_id,
            period=period,
            start_date=start_date,
            end_date=end_date,
            adjust=adjust,
            downloader_func=self.downloader.dl_history_data_stock,
            storage_save_func=get_storage().save_history_data_stock,
        )

    def download_all_stock_history(
        self,
        period: PeriodType = PeriodType.DAILY,
        adjust: AdjustType = AdjustType.QFQ,
        start_date: str = "2000-01-01",
        end_date: str = None,
    ) -> bool:
        """
        ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨çš„å†å²æ•°æ®

        Args:
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨/æœˆï¼‰
            adjust: å¤æƒç±»å‹ï¼ˆå‰å¤æƒ/åå¤æƒï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2000-01-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å¤©

        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆæ‰€æœ‰è‚¡ç¥¨çš„ä¸‹è½½
        """
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")

        logging.info(
            f"å¼€å§‹ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨å†å²æ•°æ®ï¼Œå‘¨æœŸ: {period.value}, å¤æƒ: {adjust.value}, æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}"
        )

        table_name = get_table_name(SecurityType.STOCK, period, adjust)

        try:
            if adjust == AdjustType.QFQ:
                get_storage().drop_table(table_name)

            df_stocks = get_storage().load_general_info_stock()

            if df_stocks is None or df_stocks.empty:
                logging.error("æ— æ³•è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æ•°æ®")
                return False

            stock_ids = df_stocks[COL_STOCK_ID].tolist()
            total_stocks = len(stock_ids)

            logging.info(f"å…±è·å–åˆ° {total_stocks} åªè‚¡ç¥¨ï¼Œå¼€å§‹å¤šè¿›ç¨‹ä¸‹è½½å†å²æ•°æ®...")

            result = run_history_download_mp(
                security_type=SecurityType.STOCK,
                ids=stock_ids,
                period_value=period.value,
                adjust_value=adjust.value,
                start_date=start_date,
                end_date=end_date,
                process_count=None,
                log_prefix="[Aè‚¡] ",
            )

            if result.failed == 0:
                logging.info("ğŸ‰ æ‰€æœ‰è‚¡ç¥¨å†å²æ•°æ®ä¸‹è½½æˆåŠŸï¼")
                return True

            logging.warning(
                f"âš  éƒ¨åˆ†è‚¡ç¥¨ä¸‹è½½å¤±è´¥ï¼ŒæˆåŠŸç‡: {result.success/total_stocks*100:.1f}%"
            )
            return False

        except Exception as e:
            logging.error(f"æ‰¹é‡ä¸‹è½½è‚¡ç¥¨å†å²æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def download_hk_ggt_history(
        self,
        stock_id: str,
        period: PeriodType,
        start_date: str,
        end_date: str,
        adjust: AdjustType = AdjustType.HFQ,
    ) -> bool:
        """
        ä¸‹è½½æ¸¯è‚¡é€š(GuGangTong, GGT)é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®

        Args:
            stock_id: é¦™æ¸¯è‚¡ç¥¨ä»£ç  (5ä½æ•°å­—)
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨/æœˆï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            adjust: å¤æƒç±»å‹ï¼ˆé»˜è®¤åå¤æƒï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        table_name = get_table_name(SecurityType.HK_GGT_STOCK, period, adjust)

        return self._download_history_data(
            table_name=table_name,
            security_id=stock_id,
            period=period,
            start_date=start_date,
            end_date=end_date,
            adjust=adjust,
            downloader_func=self.downloader.dl_history_data_stock_hk,
            storage_save_func=get_storage().save_history_data_hk_stock,
        )

    def download_all_hk_stock_history(
        self,
        period: PeriodType = PeriodType.DAILY,
        adjust: AdjustType = AdjustType.HFQ,
        start_date: str = "2000-01-01",
        end_date: str = None,
    ) -> bool:
        """
        ä¸‹è½½æ‰€æœ‰é¦™æ¸¯è‚¡ç¥¨çš„å†å²æ•°æ®

        Args:
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨/æœˆï¼‰
            adjust: å¤æƒç±»å‹ï¼ˆé»˜è®¤åå¤æƒï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2000-01-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å¤©

        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆæ‰€æœ‰é¦™æ¸¯è‚¡ç¥¨çš„ä¸‹è½½
        """
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")

        logging.info(
            f"å¼€å§‹ä¸‹è½½æ‰€æœ‰é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®ï¼Œå‘¨æœŸ: {period.value}, å¤æƒ: {adjust.value}, æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}"
        )

        table_name = get_table_name(SecurityType.HK_GGT_STOCK, period, adjust)
        try:
            if adjust == AdjustType.QFQ:
                get_storage().drop_table(table_name)

            df_hk_stocks = get_storage().load_general_info_hk_ggt()

            if df_hk_stocks is None or df_hk_stocks.empty:
                logging.error("æ— æ³•è·å–é¦™æ¸¯è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æ•°æ®")
                return False

            stock_ids = df_hk_stocks[COL_STOCK_ID].tolist()
            total_stocks = len(stock_ids)

            logging.info(
                f"å…±è·å–åˆ° {total_stocks} åªé¦™æ¸¯è‚¡ç¥¨ï¼Œå¼€å§‹å¤šè¿›ç¨‹ä¸‹è½½å†å²æ•°æ®..."
            )

            result = run_history_download_mp(
                security_type=SecurityType.HK_GGT_STOCK,
                ids=stock_ids,
                period_value=period.value,
                adjust_value=adjust.value,
                start_date=start_date,
                end_date=end_date,
                process_count=None,
                log_prefix="[æ¸¯è‚¡] ",
            )

            if result.failed == 0:
                logging.info("ğŸ‰ æ‰€æœ‰é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®ä¸‹è½½æˆåŠŸï¼")
                return True

            logging.warning(
                f"âš  éƒ¨åˆ†é¦™æ¸¯è‚¡ç¥¨ä¸‹è½½å¤±è´¥ï¼ŒæˆåŠŸç‡: {result.success/total_stocks*100:.1f}%"
            )
            return False

        except Exception as e:
            logging.error(f"æ‰¹é‡ä¸‹è½½é¦™æ¸¯è‚¡ç¥¨å†å²æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def download_etf_history(
        self,
        etf_id: str,
        period: PeriodType,
        start_date: str,
        end_date: str,
        adjust: AdjustType = AdjustType.QFQ,
    ) -> bool:
        """
        ä¸‹è½½ETFå†å²æ•°æ®

        Args:
            etf_id: ETFä»£ç 
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨ï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            adjust: å¤æƒç±»å‹ï¼ˆå‰å¤æƒ/åå¤æƒï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        table_name = get_table_name(SecurityType.ETF, period, adjust)

        return self._download_history_data(
            table_name=table_name,
            security_id=etf_id,
            period=period,
            start_date=start_date,
            end_date=end_date,
            adjust=adjust,
            downloader_func=self.downloader.dl_history_data_etf,
            storage_save_func=get_storage().save_history_data_etf,
        )

    def download_all_etf_history(
        self,
        period: PeriodType = PeriodType.DAILY,
        adjust: AdjustType = AdjustType.QFQ,
        start_date: str = "2000-01-01",
        end_date: str = None,
    ) -> bool:
        """
        ä¸‹è½½æ‰€æœ‰ETFçš„å†å²æ•°æ®

        Args:
            period: å‘¨æœŸç±»å‹ï¼ˆæ—¥/å‘¨ï¼‰
            adjust: å¤æƒç±»å‹ï¼ˆå‰å¤æƒ/åå¤æƒï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2000-01-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å¤©

        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆæ‰€æœ‰ETFçš„ä¸‹è½½
        """
        if end_date is None:
            from datetime import datetime

            end_date = datetime.now().strftime("%Y-%m-%d")

        logging.info(
            f"å¼€å§‹ä¸‹è½½æ‰€æœ‰ETFå†å²æ•°æ®ï¼Œå‘¨æœŸ: {period.value}, å¤æƒ: {adjust.value}, æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}"
        )

        table_name = get_table_name(SecurityType.ETF, period, adjust)

        try:
            if adjust == AdjustType.QFQ:
                get_storage().drop_table(table_name)

            # è·å–ETFåŸºæœ¬ä¿¡æ¯
            df_etfs = get_storage().load_general_info_etf()

            if df_etfs is None or df_etfs.empty:
                logging.error("æ— æ³•è·å–ETFåŸºæœ¬ä¿¡æ¯æ•°æ®")
                return False

            etf_ids = df_etfs[COL_STOCK_ID].tolist()
            total_etfs = len(etf_ids)

            logging.info(f"å…±è·å–åˆ° {total_etfs} åªETFï¼Œå¼€å§‹å¤šè¿›ç¨‹ä¸‹è½½å†å²æ•°æ®...")

            result = run_history_download_mp(
                security_type=SecurityType.ETF,
                ids=etf_ids,
                period_value=period.value,
                adjust_value=adjust.value,
                start_date=start_date,
                end_date=end_date,
                process_count=None,
                log_prefix="[ETF] ",
            )

            if result.failed == 0:
                logging.info("ğŸ‰ æ‰€æœ‰ETFå†å²æ•°æ®ä¸‹è½½æˆåŠŸï¼")
                return True

            logging.warning(
                f"âš  éƒ¨åˆ†ETFä¸‹è½½å¤±è´¥ï¼ŒæˆåŠŸç‡: {result.success/total_etfs*100:.1f}%"
            )
            return False

        except Exception as e:
            logging.error(f"æ‰¹é‡ä¸‹è½½ETFå†å²æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def download_ingredient_300(self) -> bool:
        """
        ä¸‹è½½æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        get_storage().drop_table(tb_name_ingredient_300)

        try:
            # ä¸‹è½½æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®
            df = self.downloader.dl_ingredient_300()
            if df is None or df.empty:
                logging.warning(
                    "Failed to download CSI 300 ingredient data or data is empty."
                )
                return False

            # ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“
            return get_storage().save_ingredient_300(df)

        except Exception as e:
            logging.error(f"ä¸‹è½½æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def download_ingredient_500(self) -> bool:
        """
        ä¸‹è½½ä¸­è¯500æˆåˆ†è‚¡æ•°æ®

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        get_storage().drop_table(tb_name_ingredient_500)

        try:
            df = self.downloader.dl_ingredient_500()
            if df is None or df.empty:
                logging.warning(
                    "Failed to download CSI 500 ingredient data or data is empty."
                )
                return False

            return get_storage().save_ingredient_500(df)

        except Exception as e:
            logging.error(f"ä¸‹è½½ä¸­è¯500æˆåˆ†è‚¡æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def download_daily_basic_a_stock(
        self, start_date: str | None = None, end_date: str | None = None
    ) -> bool:
        """
        ä¸‹è½½Aè‚¡æ¯æ—¥åŸºæœ¬é¢æ•°æ®ï¼ˆdaily_basicï¼‰

        Args:
            trade_date: äº¤æ˜“æ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å¤©ï¼ˆæ ¼å¼ï¼šYYYY-MM-DD æˆ– YYYYMMDDï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        last_record = get_storage().get_last_record(tb_name_daily_basic_a_stock)

        if start_date is None:
            start_date = "2010-01-01"

        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")

        if last_record is not None:
            latest_date = pd.Timestamp(last_record[COL_DATE])
            actual_start_ts = latest_date + pd.Timedelta(days=1)
            actual_start_date = actual_start_ts.strftime("%Y%m%d")

            if actual_start_ts > pd.to_datetime(end_date):
                logging.info("Aè‚¡æ¯æ—¥åŸºæœ¬é¢æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€ä¸‹è½½")
                return True
        else:
            actual_start_date = start_date

        market_calendar = mcal.get_calendar("XSHG")
        trade_days = market_calendar.schedule(
            start_date=actual_start_date, end_date=end_date
        )

        try:
            total_days = len(trade_days)
            logging.info(f"éœ€è¦ä¸‹è½½ {total_days} ä¸ªäº¤æ˜“æ—¥çš„æ¯æ—¥åŸºæœ¬é¢æ•°æ®")

            for i, date in enumerate(trade_days.index, 1):
                trade_date = date.strftime("%Y-%m-%d")

                df = self.downloader.dl_daily_basic_a_stock(trade_date)
                if df is None or df.empty:
                    logging.info(f"æ—¥æœŸ {trade_date} æ— æ•°æ®ï¼Œè·³è¿‡")
                    continue

                get_storage().save_daily_basic_a_stock(df)

                if i % 50 == 0:
                    logging.info(f"è¿›åº¦: {i}/{total_days} ({i/total_days*100:.1f}%)")

            logging.info(f"æ¯æ—¥åŸºæœ¬é¢æ•°æ®ä¸‹è½½å®Œæˆï¼Œå…±å¤„ç† {total_days} ä¸ªäº¤æ˜“æ—¥")
            return True
        except Exception as e:
            logging.error(f"ä¸‹è½½Aè‚¡æ¯æ—¥åŸºæœ¬é¢æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def download_stk_limit_a_stock(
        self, start_date: str | None = None, end_date: str | None = None
    ) -> bool:
        """
        ä¸‹è½½Aè‚¡æ¶¨è·Œåœä»·æ ¼æ•°æ®ï¼ˆstk_limitï¼‰

        Args:
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2010-01-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å¤©

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        last_record = get_storage().get_last_record(tb_name_stk_limit_a_stock)

        if start_date is None:
            start_date = "2010-01-01"

        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")

        if last_record is not None:
            latest_date = pd.Timestamp(last_record[COL_DATE])
            actual_start_ts = latest_date + pd.Timedelta(days=1)
            actual_start_date = actual_start_ts.strftime("%Y%m%d")

            if actual_start_ts > pd.to_datetime(end_date):
                logging.info("Aè‚¡æ¶¨è·Œåœä»·æ ¼æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€ä¸‹è½½")
                return True
        else:
            actual_start_date = start_date

        market_calendar = mcal.get_calendar("XSHG")
        trade_days = market_calendar.schedule(
            start_date=actual_start_date, end_date=end_date
        )

        try:
            total_days = len(trade_days)
            logging.info(f"éœ€è¦ä¸‹è½½ {total_days} ä¸ªäº¤æ˜“æ—¥çš„æ¶¨è·Œåœä»·æ ¼æ•°æ®")

            for i, date in enumerate(trade_days.index, 1):
                trade_date = date.strftime("%Y-%m-%d")

                df = self.downloader.dl_stk_limit_a_stock(trade_date=trade_date)
                if df is None or df.empty:
                    logging.info(f"æ—¥æœŸ {trade_date} æ— æ•°æ®ï¼Œè·³è¿‡")
                    continue

                get_storage().save_stk_limit_a_stock(df)

                if i % 50 == 0:
                    logging.info(f"è¿›åº¦: {i}/{total_days} ({i/total_days*100:.1f}%)")

            logging.info(f"æ¶¨è·Œåœä»·æ ¼æ•°æ®ä¸‹è½½å®Œæˆï¼Œå…±å¤„ç† {total_days} ä¸ªäº¤æ˜“æ—¥")
            return True
        except Exception as e:
            logging.error(f"ä¸‹è½½Aè‚¡æ¶¨è·Œåœä»·æ ¼æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def download_suspend_d_a_stock(
        self, start_date: str | None = None, end_date: str | None = None
    ) -> bool:
        """
        ä¸‹è½½Aè‚¡åœå¤ç‰Œæ•°æ®ï¼ˆsuspend_dï¼‰

        Args:
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸º2010-01-01
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å¤©

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        last_record = get_storage().get_last_record(tb_name_suspend_d_a_stock)

        if start_date is None:
            start_date = "2010-01-01"

        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")

        if last_record is not None:
            latest_date = pd.Timestamp(last_record[COL_DATE])
            actual_start_ts = latest_date + pd.Timedelta(days=1)
            actual_start_date = actual_start_ts.strftime("%Y%m%d")

            if actual_start_ts > pd.to_datetime(end_date):
                logging.info("Aè‚¡åœå¤ç‰Œæ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€ä¸‹è½½")
                return True
        else:
            actual_start_date = start_date

        market_calendar = mcal.get_calendar("XSHG")
        trade_days = market_calendar.schedule(
            start_date=actual_start_date, end_date=end_date
        )

        try:
            total_days = len(trade_days)
            logging.info(f"éœ€è¦ä¸‹è½½ {total_days} ä¸ªäº¤æ˜“æ—¥çš„åœå¤ç‰Œæ•°æ®")

            for i, date in enumerate(trade_days.index, 1):
                trade_date = date.strftime("%Y-%m-%d")

                # ä¸‹è½½åœç‰Œæ•°æ® (suspend_type='S')
                df_suspend = self.downloader.dl_suspend_d_a_stock(
                    suspend_type="S", trade_date=trade_date
                )
                if df_suspend is not None and not df_suspend.empty:
                    get_storage().save_suspend_d_a_stock(df_suspend)

                # ä¸‹è½½å¤ç‰Œæ•°æ® (suspend_type='R')
                df_resume = self.downloader.dl_suspend_d_a_stock(
                    suspend_type="R", trade_date=trade_date
                )
                if df_resume is not None and not df_resume.empty:
                    get_storage().save_suspend_d_a_stock(df_resume)

                if i % 50 == 0:
                    logging.info(f"è¿›åº¦: {i}/{total_days} ({i/total_days*100:.1f}%)")

            logging.info(f"åœå¤ç‰Œæ•°æ®ä¸‹è½½å®Œæˆï¼Œå…±å¤„ç† {total_days} ä¸ªäº¤æ˜“æ—¥")
            return True
        except Exception as e:
            logging.error(f"ä¸‹è½½Aè‚¡åœå¤ç‰Œæ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def download_a_stock_basic(self, list_status: str = "L") -> bool:
        """
        ä¸‹è½½Aè‚¡åŸºç¡€ä¿¡æ¯æ•°æ®ï¼ˆstock_basicï¼‰

        Args:
            list_status: ä¸Šå¸‚çŠ¶æ€ï¼Œé»˜è®¤ä¸º"L"ï¼ˆä¸Šå¸‚ï¼‰
                      L-ä¸Šå¸‚ D-é€€å¸‚ P-æš‚åœä¸Šå¸‚ G-è¿‡ä¼šæœªäº¤æ˜“

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½å¹¶ä¿å­˜
        """
        get_storage().drop_table(tb_name_a_stock_basic)

        try:
            df = self.downloader.dl_a_stock_basic(list_status=list_status)
            if df is None or df.empty:
                logging.warning(
                    "Failed to download A-stock basic info or data is empty."
                )
                return False

            logging.info(f"æˆåŠŸä¸‹è½½ {len(df)} æ¡Aè‚¡åŸºç¡€ä¿¡æ¯æ•°æ®")
            return get_storage().save_a_stock_basic(df)

        except Exception as e:
            logging.error(f"ä¸‹è½½Aè‚¡åŸºç¡€ä¿¡æ¯æ•°æ®æ—¶å‡ºé”™: {e}")
            return False
